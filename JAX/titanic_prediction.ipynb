{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4b1a0a",
   "metadata": {},
   "source": [
    "References: https://cloud.google.com/blog/products/ai-machine-learning/guide-to-jax-for-pytorch-developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3976512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import jax.numpy as jnp\n",
    "from jax.tree_util import tree_map\n",
    "from flax import nnx\n",
    "from tqdm import tqdm\n",
    "import optax\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4379e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Definition\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, samples, labels):\n",
    "        self.df = samples\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.df.iloc[idx].values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels.iloc[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def numpy_collate(batch):\n",
    "    return tree_map(jnp.asarray, default_collate(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "80229b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition in PyTorch\n",
    "class TitanicNeuralNet(nn.Module):\n",
    "    def __init__(self, num_hidden_1, num_hidden_2):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(8, num_hidden_1)\n",
    "        self.dropout = nn.Dropout(0.01)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(num_hidden_1, num_hidden_2)\n",
    "        self.linear3 = nn.Linear(num_hidden_2, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        out = self.linear3(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b1ddbf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition in Flax\n",
    "class TitanicNNX(nnx.Module):\n",
    "    def __init__(self, num_hidden_1, num_hidden_2, rngs: nnx.Rngs):\n",
    "        self.linear1 = nnx.Linear(8, num_hidden_1, rngs=rngs)\n",
    "        self.dropout = nnx.Dropout(0.01, rngs=rngs)\n",
    "        self.relu = nnx.leaky_relu\n",
    "        self.linear2 = nnx.Linear(num_hidden_1, num_hidden_2, rngs=rngs)\n",
    "        self.linear3 = nnx.Linear(num_hidden_2, 1, use_bias=False, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        out = self.linear3(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "801e7a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch training loop\n",
    "def train_torch(model, train_dataloader, eval_dataloader, num_epochs):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    for epoch in (pbar := tqdm(range(num_epochs))):\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        model.train()\n",
    "        for batch, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch)\n",
    "            loss = criterion(logits.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            train_accuracy=eval_torch(model, train_dataloader),\n",
    "            eval_accuracy=eval_torch(model, eval_dataloader),\n",
    "        )\n",
    "\n",
    "\n",
    "def eval_torch(model, eval_dataloader):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    for batch, labels in eval_dataloader:\n",
    "        logits = model(batch)\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        num_correct += (preds.squeeze() == labels).sum().item()\n",
    "        num_samples += labels.shape[0]\n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd0eb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNX training loop\n",
    "def train_nnx(model, train_dataloader, eval_dataloader, num_epochs):\n",
    "    optimizer = nnx.ModelAndOptimizer(model, optax.adam(learning_rate=0.01))\n",
    "    for epoch in (pbar := tqdm(range(num_epochs))):\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            train_step(model, optimizer, batch)\n",
    "        pbar.set_postfix(\n",
    "            train_accuracy=eval_nnx(model, train_dataloader),\n",
    "            eval_accuracy=eval_nnx(model, eval_dataloader),\n",
    "        )\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, batch):\n",
    "    def loss_fn(model):\n",
    "        logits = model(batch[0])\n",
    "        loss = optax.sigmoid_binary_cross_entropy(logits.squeeze(), batch[1]).mean()\n",
    "        return loss\n",
    "\n",
    "    grad_fn = nnx.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(model)\n",
    "    optimizer.update(grads)\n",
    "\n",
    "\n",
    "def eval_nnx(model, eval_dataloader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    for batch in eval_dataloader:\n",
    "        res = eval_step(model, batch)\n",
    "        total += res.shape[0]\n",
    "        num_correct += jnp.sum(res)\n",
    "    return num_correct / total\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model, batch):\n",
    "    logits = model(batch[0])\n",
    "    logits = logits.squeeze()\n",
    "    preds = jnp.round(nnx.sigmoid(logits))\n",
    "    return preds == batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "39882e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv(\"titanic_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "989d4393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "666037e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df = df.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "# Encode Sex as binary\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"female\": 0, \"male\": 1})\n",
    "\n",
    "# Encode Embarked as ordinal integers\n",
    "df[\"Embarked\"] = df[\"Embarked\"].map({\"C\": 0, \"Q\": 1, \"S\": 2})\n",
    "\n",
    "# Treat Missing Values\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n",
    "df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])\n",
    "\n",
    "# Feature Engineering\n",
    "df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0d99a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test split\n",
    "y = df[\"Survived\"]\n",
    "X = df.drop(\"Survived\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "96ac7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train dataset, dataloader from a pandas dataframe\n",
    "train_dataset = TitanicDataset(X_train, y_train)\n",
    "train_dataloader_jax = DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True, collate_fn=numpy_collate\n",
    ")\n",
    "train_dataloader_torch = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Create Eval dataset, dataloader from a pandas dataframe\n",
    "eval_dataset = TitanicDataset(X_test, y_test)\n",
    "eval_dataloader_jax = DataLoader(\n",
    "    eval_dataset, batch_size=64, shuffle=False, collate_fn=numpy_collate\n",
    ")\n",
    "eval_dataloder_torch = DataLoader(eval_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# PyTorch Initilization\n",
    "torch_model = TitanicNeuralNet(num_hidden_1=32, num_hidden_2=16)\n",
    "\n",
    "# Flax NNX Initilization\n",
    "flax_model = TitanicNNX(num_hidden_1=32, num_hidden_2=16, rngs=nnx.Rngs(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "db259020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PyTorch Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:01<00:00,  8.36it/s, eval_accuracy=0.821, train_accuracy=0.823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Flax Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:01<00:00,  5.24it/s, eval_accuracy=0.8324022, train_accuracy=0.81179774]\n"
     ]
    }
   ],
   "source": [
    "# Train the PyTorch model\n",
    "tqdm.write(\"Training PyTorch Model\")\n",
    "train_torch(\n",
    "    model=torch_model,\n",
    "    train_dataloader=train_dataloader_torch,\n",
    "    eval_dataloader=eval_dataloder_torch,\n",
    "    num_epochs=10,\n",
    ")\n",
    "\n",
    "# Train the Flax model\n",
    "tqdm.write(\"Training Flax Model\")\n",
    "train_nnx(\n",
    "    model=flax_model,\n",
    "    train_dataloader=train_dataloader_jax,\n",
    "    eval_dataloader=eval_dataloader_jax,\n",
    "    num_epochs=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
